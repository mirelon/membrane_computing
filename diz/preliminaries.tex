This chapter is about some basic notions of computer science which will be used through the work. We start by defining formal languages and basic models (grammars, machines) that define language families and end by defining multiset languages.

\section{Formal languages} % (fold)
\label{sec:formal_languages}

Our study is based on the classical theory of formal languages. We will recall some definitions:

\begin{definition}
An {\bf alphabet} is a finite nonempty set of symbols.
\end{definition}

\begin{definition}
A {\bf string} over an alphabet is a finite sequence of symbols from alphabet.
\end{definition}

The length of the string $s$ is denoted by $|s|$. We denote by $V^*$ the set of all strings over an alphabet $V$. By $V^+$ = $V^* - \{\eps\}$ we denote the set of all nonempty strings over V.

\begin{definition}
A {\bf language} over the alphabet $V$ is any subset of $V^*$.
\end{definition}

\begin{definition}
A {\bf family of languages} is a set of languages.
\end{definition}


\section{Formal grammars} % (fold)
\label{sec:formal_grammars}

\begin{definition}
A {\bf formal grammar} is a tuple $G = (N,T,P,\sigma)$, where
\begin{itemize}
  \item $N, T$ are disjoint alphabets of non-terminal and terminal symbols,
  \item $\sigma\in N$ is the initial non-terminal,
  \item $P$ is a finite set of rewriting rules of the form $u\rightarrow v$, with $u\in (N\cup T)^*N(N\cup T)^*$ and $v\in (N\cup T)^*$.
\end{itemize}
\end{definition}

\begin{definition}
A {\bf rewriting step} in the grammar $G$ is a binary relation $\Rightarrow$ on $(N\cup T)^*$, where $x\Rightarrow y$ only if $\exists w_1, w_2\in (N\cup T)^+$ and a rule $u\rightarrow v \in P$ such that $x=w_1uw_2$ and $y=w_1vw_2$.
\end{definition}

\begin{definition}
Language defined by a grammar $G$ is a set $L(G)=\{w\in T^*|\sigma\Rightarrow w\}$.
\end{definition}

Languages that can be generated by a formal grammar are the recursively enumerable languages $RE$.

% section formal_languages (end)

% section formal_grammars (end)

\section{Chomsky hierarchy} % (fold)
\label{sec:chomsky_hierarchy}

In this section we introduce several well-known families of languages.

\begin{definition}
A {\bf regular grammar} is a formal grammar, where the rewriting rules are of the form $u\rightarrow v$, where $u\in N$ and $v\in T^*(N\cup \{\eps\})$.
\end{definition}

\begin{definition}
A {\bf regular language} is a language generated by a regular grammar. The family of regular languages is denoted $R$.
\end{definition}

\begin{definition}
A {\bf context-free grammar} is a formal grammar, where rewriting rules are of the form $u\rightarrow v$, where $u\in N$ and $v\in (N\cup T)^*$.
\end{definition}

\begin{definition}
A {\bf context-free language} is a language generated by a context-free grammar. The family of context-free languages is denoted $CF$.
\end{definition}

\begin{definition}
A {\bf context-sensitive grammar} is a formal grammar, where rewriting rules are of the form $u\rightarrow v$, where $u\in (N\cup T)^*N(N\cup T)^*$, $v\in (N\cup T)^*$ and $|u| < |v|$.
\end{definition}

\begin{definition}
A {\bf context-sensitive language} is a language generated by a context-sensitive grammar. The family of context-sensitive languages is denoted $CS$.
\end{definition}

These families of languages forms the Chomsky hierarchy by means of inclusions: $R \subset CF \subset CS \subset RE$.

% section chomsky_hierarchy (end)

\section{Matrix grammars} % (fold)
\label{sec:matrix_grammars}

\begin{definition}
A {\bf matrix grammar} is a tuple $G = (N,T,M,\sigma)$, where:
\begin{itemize}
  \item $N, T$ are disjoint alphabets of non-terminal and terminal symbols,
  \item $\sigma\in N$ is the initial non-terminal,
  \item $M$ is a finite set of matrices, which are sequences of context-free rules of the form $u\rightarrow v$, where $u\in N$ and $v\in (N\cup T)^*$.
\end{itemize}
\end{definition}

\begin{definition}
A {\bf rewriting step} $x\Rightarrow y$ holds only if there is a matrix $(u_1\rightarrow v_1, u_2\rightarrow v_2, \ldots, u_n\rightarrow v_n) \in M$ such that for each $1\leq i\leq n$ the following holds: $x_i = x_i^{\prime}u_ix_i^{\prime\prime}$ and $x_{i+1} = x_i^{\prime}v_ix_i^{\prime\prime}$, where $x_i, x_i^{\prime}, x_i^{\prime\prime} \in (N\cup T)^*$ and $x_1 = x$ and $x_{n+1} = y$.
\end{definition}

\begin{example}
Consider the matrix grammar $G=(\{\sigma, X,Y\}, \{ a,b,c\}, M, \sigma)$, where $M$ contains three matrices: $[S\rightarrow XY], [X\rightarrow aXb, Y\rightarrow cY], [X\rightarrow ab, Y\rightarrow c]$. There are only context-free rules, yet the grammar generate the context-sensitive language $\{a^nb^nc^n|n\geq 1\}$.
\end{example}

The family of matrix grammars is denoted $MAT$.

It is known that $CF \subset MAT \subset RE$. Interestingly, $MAT \cap {a}^* \subset R$ (see \cite{Besozzi:PhD:2004}).

% section matrix_grammars (end)

\section{Register machines} % (fold)
\label{sec:register_machines}

% We will use the notion of register machine as defined in our article

\input{../inh/r-machine-definition}

% section register_machines (end)

\section{Lindenmayer systems} % (fold)
\label{sec:lindenmayer_systems}

In 1968, a Hungarian botanist and theoretical biologist Aristid Lindenmayer introduced \cite{Lindenmayer68} a new string rewriting algorithm named Lindenmayer systems (or L-systems for short). They are used by biologists and theoretical computer scientists to mathematically model growth processes of living organisms, especially plants. The difference with Chomsky grammars is that rewriting is parallel, not sequential.

The simplest version of L-systems assumes that the development of a cell is free of influence of other cells.
This type of L-systems is called $0L$ systems, where ``0'' stands for zero-sided communication between cells.

\begin{definition}
A $0L$ system is a triple $(\Sigma, P, \omega)$, where $\Sigma$ is an alphabet, $\omega$ is a word over $\Sigma$ and $P$ is a finite set of rewriting rules of the form $a\rightarrow x$, where $a\in\Sigma, x\in\Sigma^*$.
\end{definition}

It is assumed there is at least one rewriting rule for each letter of $\Sigma$. $0L$ system works in parallel way, so all the symbols are rewritten in each step.

\begin{example}
Consider a $0L$ system with alphabet $\Sigma = \{a,b\}$, initial word $\omega = a$ and rewriting rules $P = \{a\rightarrow b, b\rightarrow ab\}$.
Since in this system there is exactly one rule for every letter of the alphabet, the rewriting is thus deterministic and the generated words will be $\{a, b, ab, bab, abbab, \ldots \}$. 
\end{example}

$1L$ systems allows the rewriting rules to include context of size 1, so it allows for rules of type $yaz\rightarrow x$.

L-systems with tables ($T$) have several sets of rewriting rules instead of just one set. At one step of the rewriting process, rules belonging to the same set have to be applied. The biological motivation for introducing tables is that one may want different rules to take care of different environmental conditions (heat, light, etc.) or of different stages of development.

\begin{definition}
An extended ($E0L$) system is a pair $G_1 = (G, \Sigma_T)$, where $G = (\Sigma, P, \omega)$ is an $0L$ system, where $\Sigma_T \subseteq \Sigma$, referred to as the terminal alphabet. The language generated by $G_1$ is defined by $L(G_1) = L(G)\cap \Sigma_T^*$.
\end{definition}

Such languages are called $E0L$ languages. $E0L$ languages with tables are called $ET0L$ languages.

It is known that $CF \subset E0L \subset ET0L \subset CS$ (see section \ref{sec:chomsky_hierarchy} for definitions of $CF$ and $CS$).
% section lindenmayer_systems (end)

\section{Semilinear sets} % (fold)
\label{sec:semilinear_sets}

\begin{definition}
  A {\bf linear set} $L(c,p_1,\ldots,p_r)$ is a subset $\{c+\sum\limits_{i=1}^r|k_i\in\mathbb N\}$ of $\mathbb N^n$, where $c,p_1,\ldots,p_r\in \mathbb N^n$.
\end{definition}

We call $c$ the constant and $p_1,\ldots,p_r$ the periods of the linear set.

\begin{example}
  For $n=1$ the linear set is a subset of $\mathbb N$. For $n=1$ and $r=1$ we get an arithmetic progression.
\end{example}

\begin{example}
  $L((0,0),(0,1),(1,0))$ contains all pairs with one zero element and one non-negative element: $$\{(0,0), (1,0), (2,0), \ldots, (x,0), \ldots, (0,1), (0,2), \ldots, (0,y), \ldots\}$$.
\end{example}

\begin{definition}
  A subset of $\mathbb N^n$ is called {\bf semilinear} if it is a finite union of linear sets.
\end{definition}

% TODO Parikh mapping

% TODO Parikh's theorem

An interesting result appeared in 1968 \cite{Ito69Semilinear} that every semilinear set is a finite union of disjoint linear sets.

% section semilinear_sets (end)

\section{Petri nets} % (fold)
\label{sec:petri_nets}

Petri nets \cite{Petri62,Yen06PetriNets} were introduced by Carl Adam Petri in 1962 in his PhD thesis. A Petri net is a graphical and mathematical tool for the modeling of concurrent processes and analysis of system behavior. A Petri net is usually drawn as a directed bipartite graph with two kind of nodes. Places are represented by circles within which each small black dot denotes a token. Transitions are represented by bars. Each edge is either from a place to a transition or vice versa.

\begin{definition}
  A {\bf Petri net} is a tuple $(P, T, \varphi)$, where:
  \begin{itemize}
    \item $P$ is a finite set of places,
    \item $T$ is a finite set of transitions,
    \item $\varphi: (P\times T)\cup(T\times P)\rightarrow \mathbb N$ is a flow function.
  \end{itemize}
\end{definition}

The edges of the bipartite graph are annotated by either $\varphi(p,t)$ or $\varphi(t,p)$, where $p\in P$ and $t\in T$ are two endpoints of the arc. If $\varphi(p,t)=1$ or $\varphi(t,p)=1$, we usually omit the label.

\begin{definition}
  A {\bf marking} is a mapping $\mu: P\rightarrow \mathbb N$.
\end{definition}

The mapping $\mu$ assigns certain number of tokens to each place of the net.

\begin{definition}
  A marking $\mu_1$ {\bf covers} marking $\mu_2$, when $\forall p\in P: \mu_1(p)\geq\mu_2(p)$ - in each place there is no less tokens in $\mu_1$ than in $\mu_2$. We denote it by $\mu_1\geq\mu_2$.
\end{definition} 

\begin{definition}
  A transition $t\in T$ is {\bf enabled} at a marking $\mu$ iff $\forall p\in P, \varphi(p,t)\leq\mu(p)$.
\end{definition}

If a transition $t$ is enabled, it may fire by removing $\varphi(p,t)$ tokens from each input place $p$ and putting $\varphi(t,p^\prime)$ tokens in each output place $p^\prime$. We then write $\mu\xrightarrow{t} \mu^\prime$, where $\forall p\in P: \mu^\prime(p) = \mu(p)-\varphi(p,t)+\varphi(t,p)$.

\begin{example}
  In the Figure \ref{fig:example petri net} the Petri net has four places and two transitions. At the current marking the transition $t_1$ is enabled and the transition $t_2$ is not enabled. Firing the transition $t_1$ takes one token from the place $p_1$ and produces one token to places $p_2, p_3$ and $p_4$. In the resulting marking both transitions $t_1$ and $t_2$ are enabled.
\end{example}

\begin{definition}
  A {\bf marked Petri net} is a tuple $(P,T,\varphi,\mu_0)$, where $(P,T,\varphi)$ is a Petri net and $\mu_0$ is called the initial marking.
\end{definition}

\begin{definition}
  A sequence of transitions $\sigma = t_1\ldots t_n$ is a {\bf firing sequence} from $\mu_0$ iff $\mu_0\xrightarrow{t_1}\mu_1\xrightarrow{t_2}\ldots\xrightarrow{t_n}\mu_n$ for some markings $\mu_1,\ldots,\mu_n$. We also write $\mu_0\xrightarrow{\sigma}\mu_n$.
\end{definition}

We write $\mu_0\xrightarrow{\sigma}$ to denote that $\sigma$ is enabled and can be fired from $\mu_0$, i.e., $\mu_0\xrightarrow{\sigma}$ iff there exists a marking $\mu$ such that $\mu_0\xrightarrow{\sigma}\mu$.
The notation $\mu_0\xrightarrow{*}\mu$ is used to denote the existence of a firing sequence $\sigma$ such that $\mu_0\xrightarrow{\sigma}\mu$.

\begin{definition}
  A marking $\mu$ is reachable for a marked Petri net $\mathcal P = (P,T,\varphi,\mu_0)$ iff $\mu_0\xrightarrow{*}\mu$.
\end{definition}

\begin{definition}
  Let $\mathcal P = (P,T,\varphi,\mu_0)$ be a marked Petri net. The {\bf reachability set} of $\mathcal P$ is $R(\mathcal(P)) = \{\mu|\mu_0\xrightarrow{*}\mu\}$.
\end{definition}

A notion of reachability graph is helpful for analyzing the behavior of a Petri net as a tool for visualisation of the structure of the reachability set.

\begin{definition}
  Let $\mathcal P = (P,T,\varphi,\mu_0)$ be a marked Petri net. The {\bf reachability graph} of $\mathcal P$ is a labelled graph whose nodes are the reachable markings and edge from $\mu_1$ to $\mu_2$ is labeled with a transition $t\in T$ iff $\mu_1\xrightarrow{t}\mu_2$.
\end{definition}

\begin{figure}
  \centering
  \begin{minipage}{.4\textwidth}
    \begin{tikzpicture}
      \tikzstyle{transition}=[rectangle,thick,fill=black,minimum height=8mm]
      \node [place,tokens=3,label=above:$p_1$] (p1) {};
      \node [transition,label=above:$t_1$] (t1) [right of=p1] {}
        edge [pre] (p1);
      \node [place,tokens=0,label=right:$p_3$] (p3) [right of=t1] {}
        edge [pre] (t1);
      \node [place,tokens=0,label=right:$p_2$] (p2) [above of=p3] {}
        edge [pre] (t1);
      \node [place,tokens=0,label=right:$p_4$] (p4) [below of=p3] {}
        edge [pre] (t1);
      \node [transition,label=below:$t_2$] (t2) [below of=t1] {}
        edge [pre] (p4)
        edge [post] (p1);
    \end{tikzpicture}
    \captionof{figure}{An example Petri net}
    \label{fig:example petri net}
  \end{minipage}
  \hspace{.08\textwidth}
  \begin{minipage}{.4\textwidth}
    \begin{tikzpicture}[node distance=8mm,-triangle 45]
      \tikzstyle{every node} = [rectangle,draw]
      \tikzstyle{label} = [draw=none]
      \node (1) {3,0,0,0};
      \node [below= of 1] (2) {2,1,1,1};
      \node [below= of 2] (3) {1,2,2,2};
      \node [below= of 3] (4) {0,3,3,3};
      \node [right= of 2] (5) {3,1,1,0};
      \node [below= of 5] (6) {2,2,2,1};
      \node [below= of 6] (7) {1,3,3,2};
      \node [below= of 7] (8) {1,4,4,3};
      \node [draw=none,right= of 6] (9) {$\ldots$};
      \node [draw=none,right= of 7] (10) {$\ldots$};
      \node [draw=none,right= of 8] (11) {$\ldots$};
      \draw (1) edge node [label,right] {$t_1$} (2);
      \draw (2) edge node [label,right] {$t_1$} (3);
      \draw (3) edge node [label,right] {$t_1$} (4);
      \draw (2) edge node [label,above] {$t_2$} (5);
      \draw (3) edge node [label,above] {$t_2$} (6);
      \draw (4) edge node [label,above] {$t_2$} (7);
      \draw (5) edge node [label,right] {$t_1$} (6);
      \draw (6) edge node [label,right] {$t_1$} (7);
      \draw (7) edge node [label,right] {$t_1$} (8);
      \draw (6) edge node [label,above] {$t_2$} (9);
      \draw (7) edge node [label,above] {$t_2$} (10);
      \draw (8) edge node [label,above] {$t_2$} (11);
    \end{tikzpicture}
    \captionof{figure}{An example reachability graph}
    \label{fig:example reachability graph}
  \end{minipage}
\end{figure}

\begin{example}
  Consider a Petri net $\mathcal P$ from the Figure \ref{fig:example petri net}. Its reachability graph is in the Figure \ref{fig:example reachability graph}. $\mathcal P$ is not bounded because by alternately firing transitions $t_1$ and $t_2$ we can reach infinitely many different markings. We can also easily see that it is live, because in every marking for every transition $t\in\{t_1, t_2\}$ there is a firing sequence ending with $t$.
\end{example}

In spite of its simplicity, the applicability of the technique of reachability graph analysis is rather limited in the sense that it suffers from the state explosion phenomenon as the sizes of the reachability sets grow beyond any primitive recursive function in the worst case \cite{Yen06PetriNets}.

Coverability graph analysis offers an alternative to the techinque of reachability graph analysis by abstracting out certain details to make the graph finite. To understand the intuition behind coverability graphs, consider the Figure \ref{fig:example reachability graph} which shows a part of the reachability graph of the Petri net in the Figure \ref{fig:example petri net}. Consider the path $(3,0,0,0)\xrightarrow{t_1}(2,1,1,1)\xrightarrow{t_2}(3,1,1,0)$ along which the places $p_2$ and $p_3$ both gain an extra token in the end, i.e. $(3,0,0,0) > (3,1,1,0)$. Clearly they can be made to contain arbitrary large number of tokens by repeating the firing sequence $t_1t_2$ for a sufficient number of times, as $(3,0,0,0)\xrightarrow{t_1t_2}(3,1,1,0)\xrightarrow{t_1t_2}(3,2,2,0)\xrightarrow{t_1t_2}\ldots\xrightarrow{t_1t_2}(3,n,n,0)$, for arbitrary $n$. In order to capture the notion of a place being unbounded, we short-circuit the above infinite sequence of computation as $(3,0,0,0)\xrightarrow{t_1}(2,1,1,1)\xrightarrow{t_2}(3,\omega,\omega,0)$, where $\omega$ is a symbol denoting something being arbitrarily large. As it turns out, the coverability graph of a Petri net is always finite \cite{Karp69ParallelProgramSchemata}. The corresponding coverability graph of the example Petri net in the Figure \ref{fig:example petri net} is in the Figure \ref{fig:example coverability graph}. The algorithm for generating the coverability graph of a Petri net is shown \vpageref[above]{alg:coverability_graph}.

\begin{figure}
  \centering
  \begin{tikzpicture}[node distance=8mm,-triangle 45]
    \tikzstyle{every node} = [rectangle,draw]
    \tikzstyle{label} = [draw=none]
    \node (1) {3,0,0,0};
    \node [below= of 1] (2) {2,1,1,1};
    \node [below= of 2] (3) {1,2,2,2};
    \node [below= of 3] (4) {0,3,3,3};
    \node [right= of 2] (5) {$3,\omega,\omega,0$};
    \node [below= of 5] (6) {$2,\omega,\omega,1$};
    \node [below= of 6] (7) {$1,\omega,\omega,2$};
    \node [below= of 7] (8) {$1,\omega,\omega,3$};
    \draw (1) edge node [label,right] {$t_1$} (2);
    \draw (2) edge node [label,right] {$t_1$} (3);
    \draw (3) edge node [label,right] {$t_1$} (4);
    \draw (2) edge node [label,above] {$t_2$} (5);
    \draw (3) edge node [label,above] {$t_2$} (6);
    \draw (4) edge node [label,above] {$t_2$} (7);
    \draw (5) edge [bend right=30] node [label,left] {$t_1$} (6);
    \draw (6) edge [bend right=30] node [label,left] {$t_1$} (7);
    \draw (7) edge [bend right=30] node [label,left] {$t_1$} (8);
    \draw (6) edge [bend right=30] node [label,right] {$t_2$} (5);
    \draw (7) edge [bend right=30] node [label,right] {$t_2$} (6);
    \draw (8) edge [bend right=30] node [label,right] {$t_2$} (7);
  \end{tikzpicture}
  \caption{An example coverability graph}
  \label{fig:example coverability graph}
\end{figure}

\begin{algorithm}
  \caption{Coverability graph algorithm}\label{alg:coverability_graph}
  \begin{algorithmic}[1]
    \Procedure{CoverabilityGraph}{marked Petri net $\mathcal P = (P, T, \varphi, \mu_0)$}
      \State $\text{create a node $\mu_{init}$ such that $\mu_{init} = \mu_0$ and mark it as `new'}$
      \While{$\text{there is a `new' node $\mu$}$}
        \For{$\text{each transition $t$ enabled at $\mu$}$}
          \If{$\text{there is a node $\mu^\prime=\mu+\Delta t$}$}
            \State $\text{add an edge $\mu\xrightarrow{t}\mu^\prime$}$
          \ElsIf{$\text{there is a path $\mu_{init}\xrightarrow{*}\mu^{\prime\prime}\xrightarrow{*}\mu$ such that $\mu^{\prime\prime}<\mu+\Delta t$}$}
            \State $\text{add a `new' node $x$ with}$
            \State \hspace{\algorithmicindent}$\text{$x(p)=\omega$ if $\mu^{\prime\prime}(p)<(\mu+\Delta t)(p)$}$
            \State \hspace{\algorithmicindent}$\text{$x(p)=\mu^{\prime\prime}(p)$ otherwise}$
            \State $\text{add an edge $\mu\xrightarrow{t}x$}$
          \Else
            \State $\text{add a `new' node $x$ with $x=\mu+\Delta t$ and an edge $\mu\xrightarrow{t}x$}$
          \EndIf
        \EndFor
        \State $\text{mark $\mu$ with `old'}$
      \EndWhile
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\subsection{Analysis of behavioral properties} % (fold)
\label{sub:analysis_of_behavioral_properties}

Analysis of several behavioral properties is studied and following decidability problems are of special importance:

\subsubsection{The boundedness problem} % (fold)
\label{ssub:the_boundedness_problem}
  The boundedness problem is, given a marked Petri net $\mathcal P$, deciding whether $|R(\mathcal P)|$ is finite. This problem was first considered by Karp and Miller \cite{Karp69ParallelProgramSchemata}, where it was shown to be decidable using the technique of coverability graph analysis. A Petri net is unbounded iff an $\omega$ occurs in the corresponding coverability graph. The algorithm presented there was basically an unbounded search and consequently no complexity analysis was shown. Subsequently, a lower bound of $O(2^{cm})$ space was shown by Lipton in \cite{Lipton76Reachability}, where $m$ is the number of places in the Petri net and $c$ is a constant. Finally, an upper bound of $O(2^{cn\log{n}})$ space was given by Rackoff in \cite{Rackoff78Reachability}. Here, however, $n$ represents the size or number of bits in the problem instance and $c$ is a constant.
% subsubsection the_boundedness_problem (end)

\subsubsection{The covering problem} % (fold)
\label{ssub:the_covering_problem}
  The covering problem is, given a marked Petri net $\mathcal P$ and a marking $\mu$, deciding whether there exists $\mu^\prime\in R(\mathcal P)$ such that $\mu^\prime\geq\mu$. The complexity (both upper and lower bounds) of the covering problem can be derived along a similar line of that of the boundedness problem \cite{Rackoff78Reachability}.
% subsubsection the_covering_problem (end)

\subsubsection{The reachability problem} % (fold)
\label{ssub:the_reachability_problem}
  The reachability problem is, given a marked Petri net $\mathcal P$ and a marking $\mu$, deciding whether $\mu\in R(\mathcal P)$. This problem has attracted the most attention in the Petri net community. One reason is that the problem has many real-world applications; furthermore, it is the key to the solutions of several other Petri net problems. Before the decidability question of the reachability problem for general Petri nets was proven by Mayr in 1981 \cite{Mayr81PetriNetReachability}, a number of attempts had been made to investigate the problem for restricted classes of Petri nets, in hope of gaining more insights and developing new tools in order to conquer the general Petri net reachability problem. It should be noted that the technique of the coverability graph analysis does not answer the reachability problem as $\omega$ abstracts out the exact number of tokens that a place can accumulate, should the place be potentially unbounded.
% subsubsection the_reachability_problem (end)

\subsubsection{The containment problem} % (fold)
\label{ssub:the_containment_problem}
  The containment problem is, given two marked Petri nets $\mathcal P_1$ and $\mathcal P_2$, deciding whether $R(\mathcal P_1)\subseteq R(\mathcal P_2)$. In the late 1960's, Rabin first showed the containment problem for Petri nets to be undecidable. Even though the original work of Rabin have never been published, a new proof based on Hilbert's Tenth Problem \cite{Davis73Hilbert} was presented at MIT in 1972 \cite{Baker73PetriNetContainment}.
% subsubsection the_containment_problem (end)

\subsubsection{The equivalence problem} % (fold)
\label{ssub:the_equivalence_problem}
  The equivalence problem: given two marked Petri nets $\mathcal P_1$ and $\mathcal P_2$, deciding whether $R(\mathcal P_1) = R(\mathcal P_2)$. In 1975, Hack \cite{Hack1976PetriNetEquivalence} extended Rabin's result of the containment problem by showing the equivalence problem to be undecidable as well. The proof was also based on Hilbert's Tenth Problem.
% subsubsection the_equivalence_problem (end)

\subsubsection{The liveness problem} % (fold)
\label{ssub:the_liveness_problem}
  The liveness problem: given a marked Petri net $\mathcal P$, deciding whether for every $t\in T, \mu\in R(\mathcal P)$ there exists a sequence of transitions $\sigma$ such that $\mu\xrightarrow{\sigma t}$, i.e. $t$ is enabled after firing $\sigma$ from $\mu$. In \cite{Hack74PetriNetLiveness}, several variants of the reachability problem were shown to be recursively equivalent. Among them is the single-place zero reachability problem, i.e. the problem of determining whether a marking with no tokens in a designated place can be reached. Hack also showed the single-place zero reachability problem to be recursively equivalent to the liveness problem, which is then as well decidable.
% subsubsection the_liveness_problem (end)

% subsection analysis_of_behavioral_properties (end)

% section petri_nets (end)

\section{Vector addition systems} % (fold)
\label{sec:vector_addition_systems}

Vector addition systems were introduced by Karp and Miller \cite{Karp69ParallelProgramSchemata}, and were later shown by Hack \cite{Hack74PetriVAS} to be equivalent to Petri nets.

\begin{definition}
  A {\bf vector addition system} (VAS) is a pair $G = (x, W)$, where $x\in \mathbb N^n$ is an initial vector and $W\subseteq \mathbb Z^n$ is a finite set of vectors, where $n>0$ is called the dimension of VAS.
\end{definition}

The initial vector is seen as the initial values of multiple counters and the vectors in $W$ are seen as actions that update the counters. These counters may never drop below zero. 

\begin{definition}
  The {\bf reachability set} of the VAS $G = (x,W)$ is the set \linebreak $R(G) = \{z | \exists v_1,\ldots,v_j\in W: z=x+v_1+\ldots+v_j \wedge \forall 1\leq i\leq j: x+v_1+\ldots+v_i\geq 0\}$.
\end{definition}

\begin{definition}
  A {\bf vector addition system with states} (VASS) is a tuple $G = (x, W, Q, T, p_0)$, where:
  \begin{itemize}
    \item $(x, W)$ is a vector addition system,
    \item $Q$ is a finite set of states,
    \item $T$ is a finite set of transitions of the form $p\rightarrow(q,v)$, where $v\in W$ and $p,q\in Q$ are states,
    \item $p_0\in Q$ is the starting state.
  \end{itemize}
\end{definition}

The transition $p\rightarrow(q,v)$ can be applied at vector $y$ in state $p$ and yields the vector $y+v$ in state $q$, provided that $y+v\geq 0$.

\begin{example}
  For the Petri net in the Figure \ref{fig:example petri net}, the corresponding VAS $(x,W)$ is:
  \begin{itemize}
    \item $x=(3,0,0,0)$,
    \item $W=\{(-1,1,1,1),(1,0,0,-1)\}$.
  \end{itemize}
\end{example}

It is known \cite{Hack74PetriVAS} that Petri nets, VAS and VASS are computationally equivalent.

% section vector_addition_systems (end)

\section{Büchi automaton} % (fold)
\label{sec:buchi_automaton}

% section buchi_automaton (end)

\section{Calculi of looping sequences} % (fold)
\label{sec:calculi_of_looping_sequences}

% section calculi_of_looping_sequences (end)

\section{Graph theory} % (fold)
\label{sec:graph_theory}

% section graph_theory (end)

\section{Multisets} % (fold)
\label{sec:multisets}

\begin{definition}
A multiset over a set $X$ is a mapping $M: X\rightarrow \mathbb N$.
\end{definition}

We denote by $M(x), x\in X$ the multiplicity of $x$ in the multiset $M$.

\begin{definition}
The {\bf support} of a multiset $M$ is the set $supp(M)=\{x\in X|M(x)\geq 1\}$.
\end{definition}

It is the set of items with at least one occurrence.

\begin{definition}
A multiset is {\bf empty} when its support is empty.
\end{definition}

A multiset $M$ with finite support $X = \{x_1, x_2, \ldots, x_n\}$ can be represented by the string $x_1^{M(x_1)}x_2^{M(x_2)}\ldots x_n^{M(x_n)}$.
As elements of a multiset can also be strings, we separate them with the pipe symbol, e.g. $element|element|other\_element$.

\begin{definition}
Multiset inclusion. We say that multiset $M_1$ is included in multiset $M_2$ if $\forall x \in X: M_1(x)\leq M_2(x)$. We denote it by $M_1\subseteq M_2$.
\end{definition}

\begin{definition}
The {\bf union} of two multisets $M_1\cup M_2$ is a multiset where $\forall x \in X: (M_1\cup M_2)(x)=M_1(x)+M_2(x)$.
\end{definition}

\begin{definition}
The {\bf difference} of two multisets $M_1-M_2$ is a multiset where $\forall x \in X: (M_1-M_2)(x)=M_1(x)-M_2(x)$.
\end{definition}

\begin{definition}
Product of multiset $M$ with natural number $n\in \mathbb N$ is a multiset where $\forall x \in X: (n\cdot M)(x)=n\cdot M(x)$.  
\end{definition}

% section multisets (end)

\section{Multiset languages} % (fold)
\label{sec:multiset_languages}

The number of occurrences of a given symbol $a\in V$ in the string $w\in V^*$ is denoted by $|w|_a$.

\begin{definition}
$\Psi_V(w)=(|w|_{a_1},|w|_{a_2},\ldots,|w|_{a_n})$ is called a Parikh vector associated with the string $w\in V^*$, where $V=\{a_1,a_2,\ldots a_n\}$.
\end{definition}

\begin{definition}
For a language $L\subseteq V^*$, $\Psi_V(L)=\{\Psi_V(w)|w\in L\}$ is the Parikh mapping associated with $V$.
\end{definition}

\begin{example}
Consider an alphabet $V=\{a,b\}$ and a language $L=\{a, ab, ba\}$.
$\Psi_V(L)=\{(1,0), (1,1)\}$. Notice that Parikh image of $L$ has only 2 element while $L$ has 3 elements.
\end{example}

\begin{definition}
If $FL$ is a family of languages, by $PsFL$ we denote the family of Parikh images of languages in $FL$.
\end{definition}

% section multiset_languages (end)

\section{Bisimulations} % (fold)
\label{sec:bisimulations}
\input{bisimulation}
% section bisimulations (end)